{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Import"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# imoprt GYM stuff\n",
    "import gym\n",
    "from gym import Env\n",
    "from gym.spaces import Discrete, Box, Dict, Tuple, MultiBinary, MultiDiscrete\n",
    "\n",
    "# import helpers\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "# import stables_baselines stuff\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Types of spaces"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "Discrete(3).sample()  # gives value {0,1,2}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "Box(0, 1, shape=(3, 3)).sample()  # gives [3x3] with values in [0,1]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "Tuple((Discrete(3), Box(0, 1, shape=(3,)))).sample()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "Dict({\n",
    "    'height': Discrete(2),\n",
    "    'speed': Box(0, 100, shape=(1,)),\n",
    "    'color': Box(0, 255, shape=(4,))\n",
    "}).sample()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "MultiBinary(4).sample()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "MultiDiscrete([4, 2]).sample()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Building an environment\n",
    "\n",
    "- build an agent to give us the best shower possible\n",
    "- random temperature \n",
    "    - reward if $\\in [37, 39]$ degrees"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class ShowerEnv(Env):\n",
    "    def __init__(self) -> None:\n",
    "        self.action_space = Discrete(3)  # temp down/unchanged/up\n",
    "        self.observation_space = Box(low=0, high=100, shape=(1,))\n",
    "        self.state = 38 + random.randint(-3, 3)\n",
    "        self.shower_length = 60  # seconds\n",
    "\n",
    "\n",
    "    def step(self, action: int) -> tuple[float, float, bool, dict]:\n",
    "        self.state += action-1   # apply temp adj\n",
    "        self.shower_length -= 1  # decrease shower time\n",
    "        reward = 1 if int(self.state) in range(37, 39) else -1\n",
    "        done = self.shower_length <= 0\n",
    "        info = {}\n",
    "\n",
    "        return self.state, reward, done, info\n",
    "\n",
    "\n",
    "    def reset(self) -> float:\n",
    "        self.state = 38 + random.randint(-3, 3)\n",
    "        self.shower_length = 60\n",
    "        return self.state\n",
    "\n",
    "\n",
    "    def render(self): pass"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "env = ShowerEnv()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test Environment"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "episodes = 5\n",
    "for episode in range(1, episodes+1):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "\n",
    "    while not done:\n",
    "        env.render()\n",
    "        action = env.action_space.sample()\n",
    "        n_state, reward, done, info = env.step(action)\n",
    "        score += reward\n",
    "    print(f\"Episode: {episode}, Score: {score}\")\n",
    "env.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "log_path = os.path.join('../output', 'training', 'logs')\n",
    "model = PPO('MlpPolicy', env, verbose=1, tensorboard_log=log_path)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.learn(total_timesteps=100_000)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Save & evaluate model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "save_path = os.path.join('../output', 'training', 'saved models', 'ppo_shower')\n",
    "model.save(save_path)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "del model\n",
    "model = PPO.load(save_path)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "evaluate_policy(model, env, n_eval_episodes=100)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit"
  },
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}